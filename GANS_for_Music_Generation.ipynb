{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GANS for Music Generation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMUXng9zx0fmoX+UKeu5sJN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vijeet24/AI-Music-Generation/blob/main/GANS_for_Music_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU7V8vjuKjhK"
      },
      "source": [
        "from music21 import converter , instrument , chord ,note , stream\n",
        "import glob\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.utils import np_utils_utils\n",
        "midi = converter.sparse( 'location.mid')\n",
        "midi\n",
        "midi.show('midi')\n",
        "midi.show('text')\n",
        "element_to_parse = midi.flat.notes\n",
        "len(element_to_parse)\n",
        "for e in element_to_parse:\n",
        "    print(e,e.offset)\n",
        "notes_demo = []\n",
        "\n",
        "for ele in element_to_parse:\n",
        "    if isinstance(ele,notes.Notes):\n",
        "        notes_demo.append(str(ele.pitch))\n",
        "    \n",
        "    elif isinstance(ele,chord.Chord):\n",
        "        notes_demo.append(\"+\".join(str(n) for n in ele.normaloOrder))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing all files\n"
      ],
      "metadata": {
        "id": "k63qYDqZTGNw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcJ9Zb_quvSF"
      },
      "source": [
        "notes = []\n",
        "\n",
        "\n",
        "for files in glob.glob('/midisongs/.midi'):\n",
        "    midi = converter.parse(file)\n",
        "    \n",
        "    print('parsing is%'%file)\n",
        "    \n",
        "    element_to_parse = midi.flat.notes\n",
        "    \n",
        "    \n",
        "    for ele in element_to_parse:\n",
        "        if isinstance(ele,notes.Notes):\n",
        "            notes_demo.append(str(ele.pitch))\n",
        "\n",
        "        elif isinstance(ele,chord.Chord):\n",
        "             notes_demo.append(\"+\".join(str(n) for n in ele.normaloOrder))\n",
        "\n",
        "   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lCwPBhnGTFT9"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlJKf9FTuvfT"
      },
      "source": [
        "with open('notes','wb') as filepath:\n",
        "    pickle.dump(notes,filepath)\n",
        "with open('notes','rb') as f:\n",
        "    notes = pickle.load(f)\n",
        "n_vocab = len(set(notes))\n",
        "print(\"total notes - \",len(notes))\n",
        "print(\"unique notes - \",n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare sequential data\n"
      ],
      "metadata": {
        "id": "mBIpyk94TPeb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 100\n",
        "pitch_name = sorted(set(notes))\n",
        "ele_to_int = dict((ele,num) for ele ,num in enumerate(pitch_name)\n",
        "network_input  = []\n",
        "network_output = []\n",
        "for i in range(len(notes) - sequence_length):\n",
        "    seq_in = notes[i : i + sequence_length]\n",
        "    seq_out = notes[i + sequence_length]\n",
        "    \n",
        "    network_input.append([ele_to_int[ch] for ch in seq_in])\n",
        "    network_output.append(ele_to_int[seq_out])\n",
        "network_input\n",
        "n_pattern  = len(network_input)\n",
        "print(n_pattern)\n",
        "network_input = np.reshape(network_input,(n_pattern,sequence_length,1))\n",
        "print(network_input.shape)"
      ],
      "metadata": {
        "id": "DSuJ5ulMTVrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_network__input = network_input/(n_vocab)\n",
        "network_output = np.utils.to_categorical(network_output)\n",
        "print(normalized_network_input.shape)\n",
        "print(network_output.shape)"
      ],
      "metadata": {
        "id": "onTmOepZTd5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator fake samples\n"
      ],
      "metadata": {
        "id": "5NC6UVC5U80C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_fake_samples(n):\n",
        "\t# generate inputs in [-1, 1]\n",
        "\tX1 = -1 + rand(n) * 2\n",
        "\t# generate outputs in [-1, 1]\n",
        "\tX2 = -1 + rand(n) * 2\n",
        "\t# stack arrays\n",
        "\tX1 = X1.reshape(n, 1)\n",
        "\tX2 = X2.reshape(n, 1)\n",
        "\tX = hstack((X1, X2))\n",
        "\t# generate class labels\n",
        "\ty = zeros((n, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "q1tUqSJUU7k9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator Function\n"
      ],
      "metadata": {
        "id": "ne0qbMV6Ti3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "# define the standalone discriminator model\n",
        "def define_discriminator(n_inputs=2):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
        "\tmodel.add(Dense(1, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "# define the discriminator model\n",
        "model = define_discriminator()\n",
        "# summarize the model"
      ],
      "metadata": {
        "id": "lj9KSE0VTvxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Function"
      ],
      "metadata": {
        "id": "ZcFTFryMUDw9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim, n_outputs=2):\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
        "\tmodel.add(Dense(n_outputs, activation='linear'))\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "lZW2tCioTs5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input data"
      ],
      "metadata": {
        "id": "SdjDUEHtWUrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n, latent_dim)\n",
        "\treturn x_input\n",
        " \n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels\n",
        "\ty = zeros((n, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "Owp7373IWYuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the discriminator"
      ],
      "metadata": {
        "id": "-X_ywiGVWaPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate the discriminator and plot real and fake points\n",
        "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
        "\t# prepare real samples\n",
        "\tx_real, y_real = generate_real_samples(n)\n",
        "\t# evaluate discriminator on real examples\n",
        "\t_, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
        "\t# prepare fake examples\n",
        "\tx_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
        "\t# evaluate discriminator on fake examples\n",
        "\t_, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
        "\t# summarize discriminator performance\n",
        "\tprint(epoch, acc_real, acc_fake)\n",
        "\t# scatter plot real and fake data points\n",
        "\tpyplot.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
        "\tpyplot.scatter(x_fake[:, 0], x_fake[:, 1], color='blue')\n",
        "\tpyplot.show()"
      ],
      "metadata": {
        "id": "C0Weq81SWpwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the generator and discriminator"
      ],
      "metadata": {
        "id": "xQ9wQ-pwWxJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train the generator and discriminator\n",
        "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
        "\t# determine half the size of one batch, for updating the discriminator\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_epochs):\n",
        "\t\t# prepare real samples\n",
        "\t\tx_real, y_real = generate_real_samples(half_batch)\n",
        "\t\t# prepare fake examples\n",
        "\t\tx_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t# update discriminator\n",
        "\t\td_model.train_on_batch(x_real, y_real)\n",
        "\t\td_model.train_on_batch(x_fake, y_fake)\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tx_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = ones((n_batch, 1))\n",
        "\t\t# update the generator via the discriminator's error\n",
        "\t\tgan_model.train_on_batch(x_gan, y_gan)\n",
        "\t\t# evaluate the model every n_eval epochs\n",
        "\t\tif (i+1) % n_eval == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, d_model, latent_dim)\n",
        " \n",
        "# size of the latent space\n",
        "latent_dim = 5\n",
        "# create the discriminator\n",
        "discriminator = define_discriminator()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, discriminator)\n",
        "# train model\n",
        "train(generator, discriminator, gan_model, latent_dim)"
      ],
      "metadata": {
        "id": "Vdzr0hbOW4_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create MIDI File"
      ],
      "metadata": {
        "id": "p4TB_51KXIkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "offset = 0\n",
        "output_note = []\n",
        "\n",
        "for pattern in prediction_output:\n",
        "    \n",
        "    if(' + ' in pattern) or pattern.isdigit():\n",
        "        notes_in_chord = pattern.split('+')\n",
        "        temp_notes = []\n",
        "        \n",
        "    for current_notes in notes_in_chords:\n",
        "        new_note = notes.Notes(int(current_note))\n",
        "        new_notes.storedInstrument = instrument.Piano()\n",
        "        temp_notes.append(new_notes)\n",
        "        \n",
        "    new_chord = chord.Chord(temp_notes)\n",
        "    new_chord.offset = offset \n",
        "    output_notes.append(new_chord)\n",
        "    \n",
        "    \n",
        "    else:\n",
        "        new_notes = notes.Notes(prediction_output[4])\n",
        "        new_notes.offset = offset\n",
        "        new_notes.storedInstrument = instrument.Piano()\n",
        "        output_notes.append(new_note)\n",
        "        \n",
        "        \n",
        "    offset += 0.5\n",
        "\n",
        "\n",
        "midi_stream = stream.Stream(output_notes)\n",
        "midi_stream.write('midi', fp = 'test_output.mid')\n",
        "midi_stream.show('midi')"
      ],
      "metadata": {
        "id": "JdneJX6oXLKl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UOx5QFmUUTrl"
      }
    }
  ]
}